# 前台项目交接文档

2018年7月17日 王倩

前台项目是公司23F前台的语音交互项目，目前是人进入有效距离范围会激活装置进入识别状态，这时候讲话，墙上的投影会显示讲话内容。停止一段时间后，当前内容会粒子爆炸。人不在有效范围时麦克风周围的光环会淡去。

## 运行

项目运行在前台的电脑上（windows系统），步骤如下：

1. 确保Arduino红外部件与麦克风正常连接（通过墙上电路连接到电脑提供信号）。

2. 运行WebSocketServer程序（桌面有快捷方式，原路径为`桌面/红外完全控制/`）

   - 检验muter是否根据读到的信号修改了麦克风音量。
   - 此程序为工程部门@fanxinbang写的，其中读串口和mute麦克风部分为@wangqian写的。
   - 如果只控制麦克风，不控制动效，则运行EndpointVolumeChanger.exe(桌面有快捷方式，原路径为`桌面/MicMuter/Debug/`)

3. 运行SpeechAssist程序（桌面有快捷方式，原路径为`桌面/speech`）
   1. 将窗口拉到投影范围外（桌面右侧）

   2. 把`分隔符设置`一栏的内容修改为一个空格，原本默认好像是一长串空格。

   3. 点击`开始`按钮，此时会出现新的窗口显示前端内容

   4. 取消`切换窗口模式`，再重新勾选，此时才能调整窗口大小和位置。

   5. 依据桌面上<u>回收站</u>和<u>Chrome</u>两个程序图标的位置放置窗口的位置和大小（如下图）

      ![image-20180719185206766](/var/folders/04/16pl3v8j05d7pdkz7xc_959r0000gp/T/abnerworks.Typora/image-20180719185206766.png)

      - *注意：此时窗口的位置和最终的位置并不完全一样，所以这是如果提示动画没有恰好环绕麦克风先不着急调整。*

   6. 取消`切换窗口模式`，这时窗口周围的白边会消失，这时候提示动画应该恰好能包住麦克风，如果不能的话可以再调整。

   7. 此时，如果麦克风是收音状态，那么说话的识别结果应该会在`进行中内容`一栏显示，并且左边页面会显示内容。
      - 如果进行中内容正常，而页面没有反应，需要检查前端代码，可在浏览器中打开网页进行调试



## 源码

1. Arduino代码（@翰政写的）
   - `桌面/test2/`
2. SpeechAssist代码（工程部门开发的）
   - `桌面/speech`
3. 前端页面代码（@WangQian）
   - `桌面/speech/text-explosion-v2/`
   - 主要内容在`桌面/speech/text-explosion-v2/js/index.js` , 其中可以调整动画效果（如速度等）的参数有三部分，都用user settings标出来了。没有语音的时候测试可以用mockInput函数，需要在index.js里修改S.TEST为1或2
   - 旧前端页面代码（前端写的，@蓓蓓有修改）:`桌面/speech/text-explosion-v2/old`
4. WebSocketServer代码
   - `桌面/红外完全控制/`
   - 无Server版：`桌面/MicMuter/`
   - 无Server-WiFi版
      - `桌面/mic controller/MicMuter.py`
      - 由于接收Wi-Fi用的是python，所以用了swig把原来的muter（c++写的）包起来然后再供python使用。